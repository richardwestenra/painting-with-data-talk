<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>The Good Life</title>
		<meta name="description" content="What is best in life? How should we live, and behave towards other people? And what are our ethical duties and responsibilities as software engineers, in a world where software controls everything?" />

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/night.css">
		<link rel="stylesheet" href="css/theme/custom.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<span class="twitter-handle">@richardwestenra</span>

		<div class="reveal">
			<div class="slides">
<section data-background-color="white">
	<h1 class="title"><span>The</span> <b>Good Life</b></h1>
	<aside class="notes">
		<p>Hi, my name is Richard, and I‚Äôm here today to talk to you about what is best in life.</p>
		<p>About my background: I started out at university studying engineering, and I hated it. I quickly switched to a philosophy degree, which I loved. Now, ten years later, my job title is front end engineer. I guess engineering isn't so bad after all?</p>
	</aside>
</section>
<section>
	<h2>üëÇ Long time listener, first time caller üìû</h2>
	<aside class="notes">
		<p>I‚Äôve now been coming to FEL regularly for about four years, but this is my first time getting up on stage. When I first started coming, I was a bit too nervous to actually talk to anyone in the pub, so I‚Äôd just go straight home after the talks.</p>
		<p>But over time I started actually talking to people, and it‚Äôs become a big part of my life in London. I‚Äôve met some close friends here. I found a new coworker here. I learned about the codebar community here, and now I‚Äôm an organiser there, and you should totally come join us! And I got my current job through the FEL slack group, which you should also totally join! (Patrick, you‚Äôre welcome). And none of that would have happened without FEL, so, thanks Made by Many!</p>
		<p>But this talk isn‚Äôt about me.</p>
	</aside>
</section>
<!-- <section data-background="img/actually.png" data-background-size="contain"> -->
<section data-background="img/fedora.jpg" data-background-size="contain">
	<h3><b class="actually">Actually,</b> it's about ethics in software engineering</h3>
	<aside class="notes">
		<p>Actually, it's about ethics in software engineering.</p>
		<p>I mentioned that my official job title these days is front-end engineer, though I usually refer to myself as a developer. I've always felt a bit uncomfortable with the title of engineer, though I couldn't really put my finger on why. Maybe it felt a bit like I was claiming some sort of prestige that I hadn't earned?</p>
		<p>I didn't complete my engineering degree, and I didn't study computer science: I'm mostly self-taught. I think I‚Äôm pretty good at my job, but I still feel like I'm basically hacking stuff together a lot of the time.</p>
	</aside>
</section>
<section data-background="img/webmaster.jpg" data-background-size="contain">
	<aside class="notes">
		<p>Back in the day, we who build websites used to call ourselves webmasters - which I still think is an amazing job title. I'm kinda sad that I didn't start my career early enough to have a webmaster role in the job history section of my CV.</p>
		<p>Anyway, we were webmasters, then we were web developers, and now a lot of us are front-end engineers.</p>
		<p>I don‚Äôt think that's a bad thing, or that we should stop calling ourselves engineers - call yourself whatever you want, you can be a techno-viking or an agile pirate-ninja riding a full-stack glitter-unicorn if it makes you feel better.</p>
	</aside>
</section>
<section data-background="img/spacejam.png" data-background-size="cover">
	<h3 class="hashtag">#ObligatorySpaceJam</h3>
	<aside class="notes">
		<p>We used to be working on dinky little websites that were kind of thrown together, and now we're working on massive, professional operations that form the financial backbone of multi-billion dollar corporations. We've come a long, long way from being webmasters.</p>
		<p>But a lot of us are self-taught and didn't go through any standardised training process. And don't get me wrong, this is great, it helps ease barriers to entry. But as the industry gets more professional, it might be worth thinking about other trappings of professionalism. If we're going to call ourselves engineers, then there are ethical duties and codes of responsibility that go along with that title.</p>
	</aside>
</section>
<section data-background="img/forth.jpg" data-background-size="cover" data-background-position="right 35%">
	<aside class="notes">
		<p>A hundred years ago, civil engineering was in a similar situation to how the tech industry is now. As the industrial revolution receded behind them, engineers found new ways to use all the fancy new technologies they had developed. They grew more sophisticated in their approach, and their projects were grew in scale and complexity.</p>
		<p>But as these projects became more ambitious, there was an accompanying problem: A rise in major engineering disasters. The turn of the twentieth century saw a wave of epic structural failures, including some massive bridge collapses, <em>and also the Great Boston Molasses Flood, which you can see here</em>.</p>
	</aside>
</section>
<section data-background="img/molasses.jpg" data-background-size="contain">
	<h4 class="hashtag">#StickySituation</h4>
	<h4 class="hashtag">#TooSoon</h4>
	<aside class="notes">
		<p>and also the Great Boston Molasses Flood, which you can see here.</p>
		<p>Which, if I had to name my favourite disaster of all time, this would have to be it, just for the mental image of a tsunami of liquid sugar 50 feet high, consuming everything in its path. It's terrifying, but also, kinda delicious?</p>
		<p>Anyway these disasters had a profound effect on the way the public saw engineering, and forced engineers to confront their shortcomings.</p>
		<p>As a result, they began to regulate themselves more intensely, and established standardised codes of ethics.</p>
	</aside>
</section>
<section data-background="img/actually2.jpg" data-background-size="contain">
	<aside class="notes">
		<p>So what is Ethics? It‚Äôs not just a rhetorical cudgel that gamergate trolls used to harass feminists back in 2014, that I‚Äôm now digging out for a dated reference joke.</p>
	</aside>
</section>
<section data-background="img/conan.gif" data-background-size="cover">
	<aside class="notes">
		<p>Ethics is devoted to answering questions about what is best in life. Questions like these:</p>
	</aside>
</section>
<section data-background="img/conan.gif" data-background-size="cover">
	<dl class="ethics">
		<dt>‚ÄúWhat is best?‚Äù</dt>
		<dd class="fragment">Both spaces AND tabs&hellip; on alternating lines</dd>
		<dt>‚ÄúWhat is the	 good life?‚Äù</dt>
		<dd class="fragment">When the client is banned from feature requests</dd>
		<dt>‚ÄúHow should I live?‚Äù</dt>
		<dd class="fragment">Only support one browser</dd>
		<dt>‚ÄúHow should I behave towards other people?‚Äù</dt>
		<dd class="fragment">Interrupt them when they have their headphones on</dd>
		<dt>‚ÄúWhat is the purpose of life?‚Äù</dt>
		<dd class="fragment">Replacing everything with JavaScript</dd>
	</dl>
	<aside class="notes">
		<p>And I know what you're thinking, I can see the cogs in your software developer minds turning over. You're thinking "That's EASY!"</p>
		<p>DOWN x 4</p>
		<p>...You're all monsters. Though I'm with you on that client thing, I'd like to go one step further and ban all clients, but that's a different topic for another day.</p>
		<p>So we've established what ethics is. It's a branch of philosophy, and so we can approach it the way we approach other philosophical problems.</p>
	</aside>
</section>
<section data-background="img/chidi.jpg" data-background-size="cover">
	<aside class="notes">
		<p>Philosophers like to do things called "thought experiments", which are like real experiments but even better, because you never need to get out of your armchair.</p>
		<p>One of the most famous is the trolley problem. I'm sure many of you are already familiar with it, but for those who aren't, here's the deal.</p>
	</aside>
</section>
<section data-background="img/trolley-problem.jpg" data-background-color="white" data-background-size="contain">
	<aside class="notes">
		<p>There is a runaway trolley barreling down the railway tracks. Ahead, on the tracks, there are five people tied up and unable to move. The trolley is headed straight for them. You are standing some distance off in the train yard, next to a lever. If you pull this lever, the trolley will switch to a different set of tracks. However, you notice that there is one person on the side track. You have two options:</p>
		<p>Do nothing, and the trolley kills the five people on the main track.</p>
		<p>Pull the lever, diverting the trolley onto the side track where it will kill one person.</p>
		<p>Which is the most ethical choice? Quick show of hands, no wrong answers.</p>
	</aside>
</section>
<section data-background="img/fat-man.jpg" data-background-color="white" data-background-size="contain">
	<aside class="notes">
		<p>Now, imagine instead of a switch, you‚Äôre standing on a bridge over the tracks, next to an extremely large man. The trolley is coming, and the only way you can stop it is to push the large man onto the tracks. He‚Äôs the only one big enough to slow down the trolley.</p>
		<p>He‚Äôs looking you right in the eyes, he can see what you‚Äôre thinking, and he‚Äôs terrified, begging you not to do it. What do you do?</p>
	</aside>
</section>
<section>
	<p><div class="emoji">üõ†</div> 9 out of 10 people would<br> throw the switch,</p>
	<p><div class="emoji emoji--gap">üôÖ‚Äç‚ôÇÔ∏è</div> but only 1 in 10 people would<br> push the large man.</p>
	<aside class="notes">
		<p>The trolley problem has been the subject of many surveys, which tend to find that approximately 9 out of 10 respondents would throw the switch to kill the one and save the five.</p>
		<p>However in the large man scenario, the situation reverses, and only 1 in 10 people would push him onto the tracks.</p>
		<p>Incidentally, a 2009 survey of professional philosophers found that only 68% of them would throw the switch, 8% would not switch, and the remaining 24% had another view or could not answer. So if you‚Äôre ever tied to a train track by a cartoon villain, you‚Äôd better hope that the person by the switch isn‚Äôt a moral philosopher.</p>
		<p>So why the difference in the two outcomes?</p>
	</aside>
</section>
<section data-background="img/brain.gif" data-background-size="cover">
	<aside class="notes">
		<p>One theory is that it's because two different parts of your brain are fighting with each other.</p>
		<p>Some researchers looked at people‚Äôs brains using fMRI machines, and demonstrated that "personal" dilemmas (like pushing a man off a footbridge) engage brain regions associated with emotion, whereas "impersonal" dilemmas (like diverting the trolley by flipping a switch) engaged regions associated with controlled reasoning.</p>
		<p>And these different brain processes essentially compete with each other whenever you have to make a tough moral decision.</p>
	</aside>
</section>
<section data-background="img/mvr.jpg" data-background-color="white" data-background-size="contain">
	<aside class="notes">
		<p>Basically, inside your brain, you‚Äôve got a monkey and a robot fighting over the controls. Every time you have to make a moral decision, they duke it out.</p>
		<p>The monkey understands something simple like pushing someone off a bridge, and it's horrified. But it doesn't understand something complex like a mechanical switch, so in that situation, the gut response is reduced, and we're able to throw the lever without feeling such a crushing sense of moral horror.</p>
		<p>Now some people have a stronger monkey, and some people have a stronger robot, and that's great, because both are useful in different situations.</p>
		<p>But this is tricky for we programmers, because we work on complex problems, which might make it trickier for our monkey brains to trigger some kinds of moral responses.</p>
	</aside>
</section>
<section data-background="img/self-driving-cars.jpg" data-background-size="cover">
	<aside class="notes">
		<p>By the way, if you think it's hard for programmers to experience the full range of ethical response, then spare a thought for autonomous vehicles.</p>
		<p>Self-driving cars don‚Äôt have meat brains, and you can‚Äôt make a perfectly ethical algorithm: You can only make it as good as the humans who programmed it, and we can‚Äôt even agree on whether to use tabs or spaces.</p>
	</aside>
</section>
<section data-background="img/lidar.jpg" data-background-size="cover">
	<aside class="notes">
		<p>There are also some really tricky problems here that self-driving cars will face. Like, we'd prefer a self-driving car to swerve into a pile of trash rather than hit someone, just like a person might. But computers can make these kinds of decisions much quicker than we can, so if we decide in advance what we want them to do, they'll follow our instructions.</p>
		<p>So, we'd probably want to program our car to hit a single adult rather than bus-load of school children, right? But what if the adult is a Nobel-prize winning cancer researcher? What if the adult is driving the car? Would we want the car to sacrifice its driver? And would you choose to buy a self-driving car that's designed to sacrifice your life to save others?</p>
	</aside>
</section>
<section data-background="img/moralmachine.png" data-background-size="cover" data-background-position="center top">
	<p class="hashtag" style="margin: 0">moralmachine.mit.edu</p>
	<aside class="notes">
		<p>Some researchers at MIT came up with a nice solution for this: They built an app to mine data on people‚Äôs answers to different trolley problems, so they can use it to help them decide how autonomous cars should behave in different scenarios.</p>
		<p>The website is called Moral Machine, and you can go there right now and start judging scenarios, to help guide the self-driving cars of the future. I mean, maybe wait until the break, ok?</p>
		<p>But that doesn't help us, because we can't outsource all our moral decision-making to the internet. We're just individuals working away at computers we don't understand, and we have these ridiculous meat brains, and we have to make ethical decisions.</p>
	</aside>
</section>
<section data-background="img/volkswagen.jpg" data-background-size="cover">
	<section class="vw">
		<p>Volkswagen modified 11 million cars with software that would detect when they were being tested, and change performance to pass emissions tests.</p>
		<p class="fragment">As a result, these engines emitted nitrogen oxide pollutants up to 40 times above what is allowed by US emissions standards.</p>
		<aside class="notes">
			<p>Let's shift gears a little, and consider the Volkswagen emissions scandal. You may recall that VW added special software to millions of diesel cars, that would detect when their exhaust fumes were being checked by emissions regulators, and change performance to pass these tests.</p>
			<p>DOWN</p>
			<p>As a result, they managed to completely bypass emissions standards in the US, EU and elsewhere, for a period of about five years. Their workaround allowed them to emit up to 40 times more nitrogen oxide than what US emissions standards allow.</p>
			<p>DOWN</p>
		</aside>
	</section>
	<section class="vw">
		<p>It is estimated that air pollution causes 40,000 early deaths per year in the UK alone.</p>
		<aside class="notes">
			<p>By some estimates, air pollution causes around 40,000 early deaths per year in the UK alone.</p>
			<p>So it's pretty safe to assume that Volkswagen's technical hack is likely to result in several thousand early deaths, plus thousands more cases of asthma and other lung disease.</p>
			<p>DOWN</p>
		</aside>
	</section>
	<section class="vw">
		<p>In August, a former Volkswagen engineer was sentenced to three years in prison and fined $200,000 for his part in the scandal. Seven others are still facing charges.</p>
		<aside class="notes">
			<p>And as someone who recently started experiencing asthma symptoms for the first time since I was a child - probably because of London's air pollution - I take this pretty personally.</p>
			<p>So when I heard that one of the engineers at VW was recently imprisoned for his role in the scandal, I thought "GOOD".</p>
		</aside>
	</section>
</section>
<section data-background="img/grumpy.jpg" data-background-size="cover">
	<h1 class="grumpy">GOOD</h1>
	<aside class="notes">
		<p>But on the other hand, I've got to give them credit where it's due: VW's "defeat device" is a brilliant technical hack, frankly. It's ingenious. I can imagine that the engineers who created it must have felt pretty proud of themselves at the time.</p>
	</aside>
</section>
<section data-background="img/baddies.gif" data-background-size="contain">
	<aside class="notes">
		<p>But at the same time, you also wonder why nobody spoke up at one of their internal meetings to say hey pals, do you think that maybe we're being complete assholes here?</p>
		<p>How did they get it so wrong?</p>
	</aside>
</section>
<section data-background-color="#E5D6C7">
	<img src="img/bored-monkey.png" class="plain" />
	<aside class="notes">
		<p>Maybe it's because the monkey part of their brain was completely unable to deal with the complexity of the problem. You've got cars, and software hacks, and air pollution, and then decades later some people on the other side of the world might die... It's all a bit much for the poor monkey to handle.</p>
	</aside>
</section>
<section data-background="img/forgetful.png" data-background-color="white" data-background-size="contain">
	<aside class="notes">
		<p>We established earlier that ethical reasoning involves an internal struggle for control. And a weird thing about humans is that we can sometimes actually ‚Äòforget‚Äô to act ethically, when we‚Äôre so focussed on achieving a goal that we forget to think about consequences of our actions.</p>
		<p>Or else we justify it to ourselves in ways that don‚Äôt stand up to scrutiny, but never stop to really think it through and reflect.</p>
		<p>I‚Äôm sure we‚Äôve all done this at some point, I definitely have, and it‚Äôs led to some of my biggest screwups.</p>
	</aside>
</section>
<section data-background="img/move-fast-and-break-things.jpg" data-background-size="contain">
	<aside class="notes">
		<p>When you're just looking at a wall of code, it's very easy to forget about the human face of those who will be affected by your decisions. And unlike civil engineering, it's usually pretty easy to fix mistakes: Just roll out a patch or an update.</p>
		<p>We like to move fast and break things. But we don‚Äôt want to move fast into oncoming traffic and break people.</p>
	</aside>
</section>
<section data-background="img/reminders.png" data-background-size="cover" data-background-color="#F5F5F5">
	<aside class="notes">
		<p>There's some good news, though: If it's easy for people to act unethically when they don't think about it, then the flip side to this, is that it follows that people tend to behave more ethically when you remind them to.</p>
		<p>And it can happen even when you do it in subtle ways.</p>
	</aside>
</section>
<section>
	<img src="img/eyes.png" class="plain" alt="Eyes emoji">
	<aside class="notes">
		<p>For instance, some researchers in Newcastle found that just hanging up posters of staring human eyes in a cafetaria was enough to significantly change people's behaviour, and it made people twice as likely to clean up after themselves.</p>
		<p>If just a poster of eyes can achieve that much, then imagine what else we could accomplish with a few well-placed reminders.</p>
	</aside>
</section>
<section>
	<section>
		<h3 style="font-size: 1.4em">Moral decisions in front-end dev</h3>
		<ul class="list">
			<li class="fragment">Security</li>
			<li class="fragment">Accessibility</li>
			<li class="fragment"><s>Fraternit√©</s> Choosing clients/employers</li>
		</ul>
		<aside class="notes">
			<p>So far, I've covered a few examples of ethical dilemmas in software engineering. But what are some examples of ethical decisions that specifically affect front-end developers?</p>
			<p>DOWN</p>
			<p>Well, security, for a start. Caring about proper website security is a thankless task, where your manager or client usually won't notice if you've done your job right. But if you don't do it, you can run the risk of pulling an Equifax and completely screwing over your users.</p>
			<p>DOWN</p>
			<p>Similarly, you're making a moral decision in choosing how much effort to put into accessibility. In my experience, it's usually a choice between being lazy, and making access possible for disabled people.</p>
			<p>DOWN</p>
			<p>Deciding who to work for, and prioritising what to work on. Would you work for a tobacco company? A gun manufacturer? A gambling website, or a porn website?</p>
			<p>DOWN (optional?)</p>
		</aside>
	</section>
	<section data-background="img/Challenger_explosion.jpg" data-background-size="cover">
		<h2 style="text-shadow: -2px 4px 0 rgba(0,0,0,0.3), 0 0 40px rgba(0,0,0,0.5)">Whistleblowing</h2>
		<aside class="notes">
			<p>Btw, on the subject of security: A basic dilemma in engineering ethics is that an engineer has a duty their client or employer, but an even greater duty to report a possible risk to others from a client or employer failing to follow the engineer's directions.</p>
			<p>A classic example of this is the Challenger Space Shuttle Disaster. NASA engineers raised warnings about faulty O-rings in the boosters, and the dangers posed by the low temperatures on the morning of the launch, but managers disregarded these warnings, and failed to adequately report these technical concerns to their superiors.</p>
			<p>It was later argued that in these circumstances, the engineers had had a duty to circumvent their managers and shout about the dangers until they were heard.</p>
		</aside>
	</section>
</section>
<section>
	<h3>What can we do to<br> help developers make <br>ethical decisions?</h3>
	<aside class="notes">
		<p>So what can we do to help developers make ethical decisions?</p>
		<p>I think the best thing we can do is to use the power of reminders, and the fact that people tend to mimic the examples they see around them. So the real question is, what can we do to establish an organisational culture where people tend to act morally, and where there are lots of positive examples for us to emulate?</p>
	</aside>
</section>
<section>
	<section>
		<h3>Establish <br>codes of ethics</h3>
		<aside class="notes">
			<p>I mentioned before that many engineering industry bodies introduced formal codes of ethics in the early twentieth century.</p>
			<p>These came along with more legal regulations and barriers to entry, which I don't think is a good idea for us. But ethical codes are a great idea!</p>
			<p>DOWN</p>
		</aside>
	</section>
	<section>
		<blockquote class="code-of-ethics">
			<h3>Code of Ethics of the American Society of Civil Engineers</h3>
			<ol>
				<li>Engineers shall hold paramount the safety, health and welfare of the public and shall strive to comply with the principles of sustainable development in the performance of their professional duties.</li>
				<li>Engineers shall perform services only in areas of their competence.</li>
				<li>Engineers shall issue public statements only in an objective and truthful manner.</li>
				<li>Engineers shall act in professional matters for each employer or client as faithful agents or trustees, and shall avoid conflicts of interest.</li>
				<li>Engineers shall build their professional reputation on the merit of their services and shall not compete unfairly with others.</li>
				<li>Engineers shall act in such a manner as to uphold and enhance the honor, integrity, and dignity of the engineering profession and shall act with zero-tolerance for bribery, fraud, and corruption.</li>
				<li>Engineers shall continue their professional development throughout their careers, and shall provide opportunities for the professional development of those engineers under their supervision.</li>
			</ol>
		</blockquote>
		<aside class="notes">
			<p>These are a very good way to remind people to act ethically. Because basically, when you tell people ‚Äúhey don‚Äôt be a dick‚Äù, they will be less likely to be a dick.</p>
			<p>We already do this with codes of conduct at conferences, meetups (including Front End London), and open-source github repositories.</p>
			<p>We can do this at our organisations too. They don't have to be complicated, in fact, the simpler the better. The most important thing is to set appropriate expectations for ethical behaviour.</p>
		</aside>
	</section>
</section>
<section>
	<section>
		<h3>Establish <br>decision-making tools</h3>
		<aside class="notes">
			<p>I have a therapist friend who tells me that one of the ways they encourage ethical behaviour is to build ethics-checks into their processes.</p>
			<p>DOWN</p>
		</aside>
	</section>
	<section>
		<p><div class="emoji">üêí</div> Would you be happy for everyone to know<br> the decision you‚Äôve made?</p>
		<p><div class="emoji emoji--gap">ü§ñ</div> Do you think the consequences are acceptable?</p>
		<p><div class="emoji emoji--gap">ü§î</div> Would you recommend the same course<br> of action to others?</p>
		<aside class="notes">
			<p>So whenever they are trying to make a hard decision, they have these questions they can use,which are designed to trigger different types of emotional responses.</p>
			<p>So you've got the first one here, which I think is quite a monkey brain question, it's a good one for triggering emotional reactions like shame.</p>
			<p>So for example, if you're considerig being lazy about making your website accessible, imagine there's a disabled person sitting next to you, and think about whether you'd feel comfortable explaining your code choices to them.</p>
			<p>The second one seems designed to trigger more of a consequentialist response. It's maybe a bit of a rationalist, robot-brained approach?</p>
			<p>The last one reminds of Immanuel Kant's categorical imperative, that you should only do something if you'd be okay with it being a universal law. So that's cool too, if Kant's your thing.</p>
			<p>Overall I really like them: Good job psychotherapists!</p>
		</aside>
	</section>
</section>
<section>
	<section>
		<h3>Empower developers<br> to feel able to say no</h3>
		<aside class="notes">
			<p>A few years ago, I was working for an consultancy, who assigned me to a website project for a client I didn't approve of. But I got so invested in solving the technical aspects of the project, that I didn't stop to think about whether I was morally okay with working for this client, until I was already deeply invested. I moaned about the client to some colleagues, and they told me, if you didn't want to work for this client, that's fine, but you should have said something at the start of this project.</p>
			<p>It made me realise that it was okay to say no to client projects, but also that the appropriate time to do that is before you start work. The later you leave it, the harder it is to say no.</p>
			<p>The next time a dodgy client came along, I felt more comfortable expressing my concerns up-front, and we ended up turning down the client.</p>
			<!-- <p>DOWN (optional)</p> -->
		</aside>
	</section>
	<!-- <section data-background="img/you-wouldnt.png" data-background-color="black" data-background-size="contain">
		<aside class="notes">
			<p>I tend to think of this as being like encouraging developers to submit bug reports and point out errors. If everyone feels empowered to speak up, then you're all better off.</p>
		</aside>
	</section> -->
</section>
<section>
	<h3>Encourage developers <br>to meet users</h3>
	<aside class="notes">
		<p>Finally, we can help engineers to develop more empathy for their users, by encouraging them to meet them in person. A great way to do this is to get devs to sit in on user-testing sessions.</p>
		<p>A nice additional benefit of this is that empathy for your users helps you design better user-centred solutions, too. Win-win.</p>
	</aside>
</section>
<section>
	<h1>Thanks!</h1>
	<p style="margin: 1em 0 0.8em">Don't forget to like and subscribe üëç</p>
	<a class="social" style="left:-1.85em" href="http://twitter.com/richardwestenra"> <i class="icon-twitter"></i> twitter.com/<b>richardwestenra</b></a>
	<a class="social" style="left:-1.85em" href="http://github.com/richardwestenra"> <i class="icon-github"></i> github.com/<b>richardwestenra</b></a>
	<a class="social" style="left:0em" href="mailto:richard@richardwestenra.com"> <i class="icon-email"></i> richard@<b>richardwestenra</b>.com</a>
	<a class="social" style="left:2.17em" href="http://richardwestenra.com"> <i class="icon-home"></i> <b>richardwestenra</b>.com</a>
	<!-- <a class="social" style="left:-2.8em" href="http://linkedin.com/in/richardwestenra"> <i class="icon-linkedin"></i> linkedin.com/in/<b>richardwestenra</b></a> -->
	<!-- <a class="social" style="left:-2.5em" href="http://facebook.com/richardwestenra"> <i class="icon-facebook"></i> facebook.com/<b>richardwestenra</b></a> -->
	<aside class="notes">
		If you have have any more suggestions that you think I've missed, please come talk to me, either in the pub afterwards, or get in touch online using one of my imaginative usernames.
	</aside>
</section>
<section>
	<section>
		<img src="https://www.quantumblack.com/img/logo.svg" class="plain" alt="">
		<br/>
		<br/>
		<br/>
		<br/>
		<h3>We're hiring, I think</h3>
		<aside class="notes">
			Finally: QuantumBlack.<br>
			I know the company name sounds kind of sinister, but we‚Äôre actually a completely legitimate organisation.
			<p>DOWN (optional)</p>
		</aside>
	</section>
	<section data-background="img/bond-lair.jpg" data-background-size="contain">
		<aside class="notes">
			We have lots of offices around the world, this is our Boston office
			<p>DOWN</p>
		</aside>
	</section>
	<!-- <section data-background="img/bond-lair2.png" data-background-size="contain">
		<aside class="notes">
			And this is a new one that we just opened in Sydney.
			<p>DOWN</p>
		</aside>
	</section> -->
	<section data-background="img/henchmen.jpg" data-background-size="contain">
		<aside class="notes">
			Here are some of my friendly coworkers, you can see we're a diverse team.<br/>
			We could do better with representation in leadership, but we're working on it.
			<p>DOWN</p>
		</aside>
	</section>
	<section data-background="img/blofeld.png" data-background-size="contain">
		<aside class="notes">
			and this is my boss, he's a big animal-lover.
		</aside>
	</section>
</section>
<section>
	<img src="img/socrates.jpg" class="plain" alt="Socrates" width="550px">
	<h2>Questions?</h2>
	<aside class="notes">
		<p>I hope you enjoyed my talk. I'm happy to try to answer any questions you might have!</p>
		<p>However you might find that, like Socrates here, I only know that I know nothing.</p>
	</aside>
</section>
			</div>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				history: true,
				// showNotes: true,
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
